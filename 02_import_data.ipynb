{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2ox5gcHFT-B",
        "outputId": "893616a1-38cf-4f5e-d38c-b27db65bc62c"
      },
      "outputs": [],
      "source": [
        "# IGNORE THIS IF NOT USED IN GOOGLE COLAB\n",
        "# !pip install susi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BeUAXgSDG56z"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import susi\n",
        "import json\n",
        "import pickle\n",
        "import requests\n",
        "import pandas as pd\n",
        "from susi.SOMPlots import plot_nbh_dist_weight_matrix, plot_umatrix, plot_estimation_map, plot_som_histogram\n",
        "from bokeh.models import ColumnDataSource, LabelSet\n",
        "from bokeh.plotting import figure, show"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "radio_data_path = '../datasets-preparation/radio.pkl'\n",
        "fma_data_path = '../datasets-preparation/fma.pkl'\n",
        "xenocanto_data_path = '../datasets-preparation/xenocanto.pkl'\n",
        "\n",
        "radio_data = pickle.load(open(radio_data_path, 'rb'))\n",
        "# /\\.\\/(\\w*?)\\//g\n",
        "data_length = len(radio_data['features'])\n",
        "radio_data['known'] = ['NaN'] * data_length\n",
        "index = 0\n",
        "for path in radio_data['Sample_audio']:\n",
        "    if './known/' in path:\n",
        "       radio_data['known'][index] = 'known'\n",
        "    else:\n",
        "        radio_data['known'][index] = 'unknown'\n",
        "    index+=1\n",
        "\n",
        "fma_data = pickle.load(open(fma_data_path, 'rb'))\n",
        "\n",
        "xenocanto_data = pickle.load(open(xenocanto_data_path, 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "fWC-HJpuoFMu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3000\n",
            "3000\n",
            "1000\n",
            "1000\n"
          ]
        }
      ],
      "source": [
        "\n",
        "current_df = fma_data\n",
        "data_length = len(current_df)\n",
        "train_amount = math.floor(len(current_df) / 4) * 3\n",
        "current_df_train = current_df.loc[0:train_amount-1]\n",
        "train_data = current_df.loc[0:train_amount-1]\n",
        "print(len(train_data))\n",
        "train_data = [np.ravel(item) for item in train_data['mfcc']]\n",
        "print(len(train_data))\n",
        "test_data = current_df.loc[train_amount:data_length-1]\n",
        "current_df_test = current_df.loc[train_amount:data_length-1]\n",
        "print(len(test_data))\n",
        "test_data = [np.ravel(item) for item in test_data['mfcc']]\n",
        "print(len(test_data))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<susi.SOMClustering.SOMClustering at 0x282f56d90>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data_length = len(train_data)\n",
        "\n",
        "\n",
        "# 5 * sqrt(number of training samples)\n",
        "grid = math.ceil(5 * math.sqrt(train_data_length))\n",
        "grid = math.floor(math.sqrt(grid))\n",
        "print(grid)\n",
        "# this returns \"ideal\" grid size\n",
        "# maybe is a parameter that students can play around as well\n",
        "\n",
        "# @title Unsupervised Learning\n",
        "som = susi.SOMClustering(\n",
        "    n_rows=grid,\n",
        "    n_columns=grid,\n",
        "    n_iter_unsupervised=10000\n",
        ")\n",
        "som.fit(train_data)\n",
        "# print(\"SOM fitted!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "som_fma = som\n",
        "with open('SOM/som_fma.pkl', 'wb') as _file:\n",
        "    pickle.dump(som_fma, _file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "u_matrix = som.get_u_matrix()\n",
        "plot_umatrix(u_matrix, grid, grid)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
        "\n",
        "\n",
        "\n",
        "clusters = som.get_clusters(np.asarray(test_data[0:100]))\n",
        "plt.scatter(x=[c[1] for c in clusters], y=[c[0] for c in clusters], alpha=0.2)\n",
        "# plt.gca().invert_yaxis()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# f = open('../data.json')\n",
        "# json_data = json.load(f)\n",
        "# print(json_data)\n",
        "# type(json_data)\n",
        "data_from_node = []\n",
        "for x in range(grid):\n",
        "    for y in range(grid):\n",
        "        obj = {\"x\": x, \"y\": y}\n",
        "        data = som.get_datapoints_from_node((x, y))\n",
        "        obj[\"data\"] = data\n",
        "        obj[\"val\"] = len(data)\n",
        "        data_from_node.append(obj)\n",
        "\n",
        "print(data_from_node)\n",
        "\n",
        "\n",
        "def get_min_max(data):\n",
        "    values_arr = [x[\"val\"] for x in data]\n",
        "    minimum = min(values_arr)\n",
        "    maximum = max(values_arr)\n",
        "    avg = np.average(values_arr)\n",
        "    return [minimum, maximum, avg]\n",
        "\n",
        "\n",
        "print(get_min_max(data_from_node))\n",
        "\n",
        "\n",
        "# from https://stackoverflow.com/questions/1969240/mapping-a-range-of-values-to-another\n",
        "def map(value, original_min, original_max, mapped_min, mapped_max):\n",
        "    # Figure out how 'wide' each range is\n",
        "    leftSpan = original_max - original_min\n",
        "    rightSpan = mapped_max - mapped_min\n",
        "\n",
        "    # Convert the left range into a 0-1 range (float)\n",
        "    valueScaled = float(value - original_min) / float(leftSpan)\n",
        "\n",
        "    # Convert the 0-1 range into a value in the right range.\n",
        "    return round(mapped_min + (valueScaled * rightSpan))\n",
        "\n",
        "\n",
        "def clamp(n, smallest, largest):\n",
        "    return max(smallest, min(n, largest))\n",
        "\n",
        "\n",
        "\n",
        "def make_color_palette(data):\n",
        "    minmax = get_min_max(data)\n",
        "    length = len(data)\n",
        "    for i in range(length):\n",
        "        item = data[i]\n",
        "        r = map(item[\"val\"], minmax[0], minmax[2], 0, 255)\n",
        "        r = clamp(r, 0, 255)\n",
        "        g = clamp(map(item[\"val\"], minmax[0], minmax[2], 30, 85), 0, 255)\n",
        "        b = clamp(map(item[\"val\"], minmax[0], minmax[2], 0, 255), 0, 155)\n",
        "        color = \"#%02x%02x%02x\" % (r, g, b)\n",
        "        item[\"color-hex\"] = color\n",
        "        color = [r / 255, g / 255, b / 255]\n",
        "        item[\"color-rgb\"] = color\n",
        "\n",
        "\n",
        "make_color_palette(data_from_node)\n",
        "print(data_from_node)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = [x['x'] for x in data_from_node]\n",
        "Y = [x['y'] for x in data_from_node]\n",
        "C = [x['color-rgb'] for x in data_from_node]\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "\n",
        "ax.scatter(X, Y, c = C)\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Projecting FMA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kn-D3Oi9rIM3"
      },
      "outputs": [],
      "source": [
        "# @title update dataframe\n",
        "projection = som.transform(test_data)\n",
        "X = [x[0] for x in projection]\n",
        "Y = [x[1] for x in projection]\n",
        "\n",
        "current_df_test['proj_x'] = X\n",
        "current_df_test['proj_y'] = Y\n",
        "proj = [[x[0], x[1]] for x in projection]\n",
        "current_df_test['proj'] = proj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "def build_color_palette(unique):\n",
        "    result = {}\n",
        "    for name in unique:\n",
        "        # Generating a random number in between 0 and 2^24\n",
        "        color = random.randrange(0, 2**24)\n",
        "        # Converting that number from base-10 (decimal) to base-16 (hexadecimal)\n",
        "        hex_color = hex(color)\n",
        "        std_color = \"#\" + hex_color[2:]\n",
        "        result[name] = std_color\n",
        "    print(result)\n",
        "    return result\n",
        "\n",
        "def assign_colors(df, palette, header):\n",
        "    colors = []\n",
        "    for item in df[header]: #this needs to be set in a variable\n",
        "        color = palette[item]\n",
        "        colors.append(color)\n",
        "    df['colors'] = colors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# extract all the nodes given the genres\n",
        "# .drop_duplicates(subset=['brand'])\n",
        "field = \"Genre\"\n",
        "unique_values = current_df_test[field].unique()\n",
        "projection_df = pd.DataFrame(columns=current_df_test.columns.to_list())\n",
        "print(projection_df)\n",
        "for value in unique_values:\n",
        "    temp = current_df_test.loc[current_df_test[field] == value]\n",
        "    temp = temp.drop_duplicates(subset=['proj'])\n",
        "    projection_df = pd.concat([projection_df, temp], ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "field = \"Genre\"\n",
        "unique_values = current_df_test[field].unique()\n",
        "print(len(unique_values))\n",
        "palette = build_color_palette(unique_values)\n",
        "assign_colors(current_df_test, palette, field)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFf7HCqipTPT"
      },
      "outputs": [],
      "source": [
        "# @title Build Visualization with Bokeh\n",
        "# add a variable for the header to be used for the labels\n",
        "\n",
        "# test_data = projection_df\n",
        "\n",
        "'''\n",
        "make a cell for the two lines below to have the\n",
        "tst data be either specific rows\n",
        "or specific Genre\n",
        "'''\n",
        "\n",
        "test_data = current_df_test.loc[current_df_test['Genre'] == 'Rock']\n",
        "# test_data = current_df_test.loc[3000:3699]\n",
        "\n",
        "TITLE = \"SOM Visualization\"\n",
        "TOOLS = \"hover,pan,wheel_zoom,box_zoom,reset,save\"\n",
        "\n",
        "\n",
        "\n",
        "p = figure(tools=TOOLS, toolbar_location=\"above\", width=1200, title=TITLE)\n",
        "p.toolbar.logo = \"grey\"\n",
        "p.background_fill_color = \"#efefef\"\n",
        "p.xaxis.axis_label = \"X-axis\"\n",
        "p.yaxis.axis_label = \"Y-axis\"\n",
        "p.grid.grid_line_color = \"white\"\n",
        "p.hover.tooltips = [\n",
        "    (field, \"@\" + field),\n",
        "]\n",
        "\n",
        "\n",
        "source = ColumnDataSource(test_data)\n",
        "\n",
        "p.scatter(\"proj_x\", \"proj_y\", size=12, source=source, color=\"colors\",line_color=\"black\", alpha=0.9)\n",
        "\n",
        "labels = LabelSet(x=\"X-axis\", y=\"Y-axis\", text=\"symbol\", y_offset=8,\n",
        "                  text_font_size=\"11px\", text_color=\"#555555\",\n",
        "                  source=source, text_align='center')\n",
        "p.add_layout(labels)\n",
        "\n",
        "show(p)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## TO DO \n",
        "* assign unique name for all datasets for what needs to be shown aka what is the equivalent of Genre for radio and xenocanto\n",
        "* make projecting the other datasets possible\n",
        "* add save functionality for colab integration from [here](https://docs.bokeh.org/en/latest/docs/reference/io.html#bokeh.io.save)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Projecting Other Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# projection_df[radio_data['mfcc'] != Nan]\n",
        "projection_df = radio_data\n",
        "projection_features = [np.ravel(item) for item in projection_df['mfcc']]\n",
        "index = 0\n",
        "nan_indexes = []\n",
        "for f in projection_features:\n",
        "    if np.isnan(f)[0] == True:\n",
        "        nan_indexes.append(index)\n",
        "    index+=1\n",
        "\n",
        "print(nan_indexes)\n",
        "\n",
        "projection_df = projection_df.drop(nan_indexes)\n",
        "projection_features = np.delete(projection_features, nan_indexes, axis=0)\n",
        "print(len(projection_features))\n",
        "print(len(projection_df))\n",
        "\n",
        "projection = som.transform(projection_features)\n",
        "X = [x[0] for x in projection]\n",
        "Y = [x[1] for x in projection]\n",
        "\n",
        "projection_df['proj_x'] = X\n",
        "projection_df['proj_y'] = Y\n",
        "proj = [[x[0], x[1]] for x in projection]\n",
        "projection_df['proj'] = proj\n",
        "\n",
        "\n",
        "field = \"known\"\n",
        "unique_values = projection_df[field].unique()\n",
        "print(len(unique_values))\n",
        "palette = build_color_palette(unique_values)\n",
        "assign_colors(projection_df, palette, field)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title Build Visualization with Bokeh\n",
        "# add a variable for the header to be used for the labels\n",
        "\n",
        "test_data = projection_df\n",
        "# test_data = current_df_test.loc[current_df_test['Genre'] == 'Rock']\n",
        "# test_data = current_df_test.loc[3000:3699]\n",
        "\n",
        "TITLE = \"SOM Visualization\"\n",
        "TOOLS = \"hover,pan,wheel_zoom,box_zoom,reset,save\"\n",
        "\n",
        "\n",
        "\n",
        "p = figure(tools=TOOLS, toolbar_location=\"above\", width=1200, title=TITLE)\n",
        "p.toolbar.logo = \"grey\"\n",
        "p.background_fill_color = \"#efefef\"\n",
        "p.xaxis.axis_label = \"X-axis\"\n",
        "p.yaxis.axis_label = \"Y-axis\"\n",
        "p.grid.grid_line_color = \"white\"\n",
        "p.hover.tooltips = [\n",
        "    (field, \"@\" + field),\n",
        "]\n",
        "\n",
        "\n",
        "source = ColumnDataSource(test_data)\n",
        "\n",
        "p.scatter(\"proj_x\", \"proj_y\", size=12, source=source, color=\"colors\",line_color=\"black\", alpha=0.9)\n",
        "\n",
        "labels = LabelSet(x=\"X-axis\", y=\"Y-axis\", text=\"symbol\", y_offset=8,\n",
        "                  text_font_size=\"11px\", text_color=\"#555555\",\n",
        "                  source=source, text_align='center')\n",
        "p.add_layout(labels)\n",
        "\n",
        "show(p)\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Old Stuff will be removed soon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bh-BOAHjHefH"
      },
      "outputs": [],
      "source": [
        "# @title Import Data\n",
        "url_radio_data_noise = 'https://radioexplorations.ch/study-2/data/df_fma_entropy_radio.json'\n",
        "url_radio_data_fingerprint = 'https://radioexplorations.ch/study-2/data/df_radio_data.json'\n",
        "url_fma_data_noise = 'https://radioexplorations.ch/study-2/data/df_fma_entropy_data.json'\n",
        "url_fma_data_fingerprint = 'https://radioexplorations.ch/study-2/data/df_small_data.json'\n",
        "\n",
        "# get radio noise dataset\n",
        "radio_data_noise = requests.get(url_radio_data_noise)\n",
        "radio_data_noise = radio_data_noise.json()\n",
        "radio_data_noise.pop('bmus-proj')\n",
        "df_radio_noise = pd.DataFrame.from_dict(radio_data_noise)\n",
        "\n",
        "# get radio fingerprint dataset\n",
        "radio_data_fingerprint = requests.get(url_radio_data_fingerprint)\n",
        "radio_data_fingerprint = radio_data_fingerprint.json()\n",
        "radio_data_fingerprint.pop('bmus-proj')\n",
        "df_radio_fingerprint = pd.DataFrame.from_dict(radio_data_fingerprint)\n",
        "\n",
        "# get fma noise dataset\n",
        "fma_data_noise = requests.get(url_fma_data_noise)\n",
        "fma_data_noise = fma_data_noise.json()\n",
        "df_fma_noise = pd.DataFrame.from_dict(fma_data_noise)\n",
        "\n",
        "# get fma fingerprint dataset\n",
        "fma_data_fingerprint = requests.get(url_fma_data_fingerprint)\n",
        "fma_data_fingerprint = fma_data_fingerprint.json()\n",
        "df_fma_fingerprint = pd.DataFrame.from_dict(fma_data_fingerprint)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "WIuiRTkFIYhd",
        "outputId": "edebfce1-14ab-4ae5-ae9b-4e6878e55024"
      },
      "outputs": [],
      "source": [
        "# @markdown Display the trining data\n",
        "fig, ax = plt.subplots(\n",
        "    nrows=1, ncols=1, figsize=(12, 3.5), \n",
        "    subplot_kw=dict(xticks=[], yticks=[])\n",
        "    )\n",
        "shape_x = 50 # @param{type:\"integer\"}\n",
        "shape_y = 60 # @param{type:\"integer\"}\n",
        "ax.imshow(train_data.reshape(shape_x, shape_y, 3))\n",
        "ax.title.set_text('Training Data')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
